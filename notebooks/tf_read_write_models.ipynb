{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Download Done!\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "print(\"Download Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate  = 1e-3\n",
    "training_iters = 100000\n",
    "batch_size     = 50\n",
    "display_step   = 100\n",
    "save_path      = None\n",
    "logs_path      = \"TensorBoard/lenet\"\n",
    "model_path     = \"Model/lenet\"\n",
    "\n",
    "# network parameters\n",
    "n_input   = 784  # input data (img shape: 28 * 28)\n",
    "n_classes = 10   # total classes (0-9 digits)\n",
    "dropout   = 0.75 # dropout, probability to keep units\n",
    "\n",
    "# tf graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input], name = 'X')\n",
    "y = tf.placeholder(tf.float32, [None, n_classes], name = 'Y')\n",
    "keep_prob = tf.placeholder(tf.float32, name = \"keep_prob\") #dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some wrappers for simplicity\n",
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial, name = name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial, name = name)\n",
    "\n",
    "def conv2d(x, W, b, strides = 1):\n",
    "    x = tf.nn.conv2d(x, W,                               \\\n",
    "                     strides = [1, strides, strides, 1], \\\n",
    "                     padding = \"SAME\")\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def max_pool(x, k = 2):\n",
    "    return tf.nn.max_pool(x,                      \\\n",
    "                          ksize   = [1, k, k, 1], \\\n",
    "                          strides = [1, k, k, 1], \\\n",
    "                          padding = \"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # 5 x 5 conv,  1 input , 32 outputs\n",
    "    \"W_conv1\": weight_variable([5, 5, 1, 32], name = \"W_conv1\"),\n",
    "    # 5 x 5 conv, 32 inputs, 64 outputs\n",
    "    \"W_conv2\": weight_variable([5, 5, 32, 64], name = \"W_conv2\"),\n",
    "    # 7 * 7 * 64 inputs, 1024 outputs\n",
    "    \"W_fc1\": weight_variable([7 * 7 * 64, 1024], name = \"W_fc1\"),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    \"W_out\": weight_variable([1024, n_classes], name = \"W_out\")\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"b_conv1\": bias_variable([32], name = \"b_conv1\"),\n",
    "    \"b_conv2\": bias_variable([64], name = \"b_conv2\"),\n",
    "    \"b_fc1\": bias_variable([1024], name = \"b_fc1\"),\n",
    "    \"b_out\": bias_variable([n_classes], name = \"b_out\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def lenet(x, weights, biases, dropout):\n",
    "    # reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # conv layer-1\n",
    "    h_conv1 = conv2d(x, weights[\"W_conv1\"], biases[\"b_conv1\"])\n",
    "    h_pool1 = max_pool(h_conv1, k = 2)\n",
    "\n",
    "    # conv layer-2\n",
    "    h_conv2 = conv2d(h_pool1, weights[\"W_conv2\"], biases[\"b_conv2\"])\n",
    "    h_pool2 = max_pool(h_conv2, k = 2)\n",
    "\n",
    "    # full connection\n",
    "    # reshape conv2 output to fit fully connected layer input\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, weights[\"W_fc1\"].get_shape().as_list()[0]])\n",
    "    h_fc1 = tf.nn.relu(tf.add(tf.matmul(h_pool2_flat, weights[\"W_fc1\"]), biases[\"b_fc1\"]))\n",
    "\n",
    "    # apply dropout\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, dropout)\n",
    "\n",
    "    # output layer, class prediction\n",
    "    out = tf.add(tf.matmul(h_fc1_drop, weights[\"W_out\"]), biases[\"b_out\"])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(x, weights, biases, keep_prob):\n",
    "    return lenet(x, weights, biases, keep_prob)\n",
    "\n",
    "def get_cost(y, y_hat):\n",
    "    cost = tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = y_hat)\n",
    "    return tf.reduce_mean(cost)\n",
    "\n",
    "def get_accuracy(y, y_hat):\n",
    "    correct_pred = tf.equal(tf.argmax(y_hat, 1), tf.argmax(y, 1))\n",
    "    return tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "y_hat = tf.identity(get_pred(x, weights, biases, keep_prob), \"Y_hat\")\n",
    "\n",
    "# define loss and optimizer\n",
    "cost = tf.identity(get_cost(y, y_hat), \"cost\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "# evaluate model\n",
    "accuracy = tf.identity(get_accuracy(y, y_hat), \"accuracy\")\n",
    "\n",
    "tf.summary.scalar(\"loss\", cost)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "# 'Saver' op to save and restore all the variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter              : 5000  \n",
      "Minibatch Loss    : 0.07\n",
      "Training  Accuacy : 0.98 \n",
      "\n",
      "Iter              : 10000  \n",
      "Minibatch Loss    : 0.08\n",
      "Training  Accuacy : 0.96 \n",
      "\n",
      "Iter              : 15000  \n",
      "Minibatch Loss    : 0.05\n",
      "Training  Accuacy : 0.98 \n",
      "\n",
      "Iter              : 20000  \n",
      "Minibatch Loss    : 0.04\n",
      "Training  Accuacy : 1.00 \n",
      "\n",
      "Iter              : 25000  \n",
      "Minibatch Loss    : 0.02\n",
      "Training  Accuacy : 1.00 \n",
      "\n",
      "Iter              : 30000  \n",
      "Minibatch Loss    : 0.23\n",
      "Training  Accuacy : 0.96 \n",
      "\n",
      "Iter              : 35000  \n",
      "Minibatch Loss    : 0.02\n",
      "Training  Accuacy : 1.00 \n",
      "\n",
      "Iter              : 40000  \n",
      "Minibatch Loss    : 0.03\n",
      "Training  Accuacy : 1.00 \n",
      "\n",
      "Iter              : 45000  \n",
      "Minibatch Loss    : 0.06\n",
      "Training  Accuacy : 0.96 \n",
      "\n",
      "Iter              : 50000  \n",
      "Minibatch Loss    : 0.01\n",
      "Training  Accuacy : 1.00 \n",
      "\n",
      "Iter              : 55000  \n",
      "Minibatch Loss    : 0.02\n",
      "Training  Accuacy : 1.00 \n",
      "\n",
      "Iter              : 60000  \n",
      "Minibatch Loss    : 0.01\n",
      "Training  Accuacy : 1.00 \n",
      "\n",
      "Iter              : 65000  \n",
      "Minibatch Loss    : 0.03\n",
      "Training  Accuacy : 0.98 \n",
      "\n",
      "Iter              : 70000  \n",
      "Minibatch Loss    : 0.01\n",
      "Training  Accuacy : 1.00 \n",
      "\n",
      "Iter              : 75000  \n",
      "Minibatch Loss    : 0.01\n",
      "Training  Accuacy : 1.00 \n",
      "\n",
      "Iter              : 80000  \n",
      "Minibatch Loss    : 0.01\n",
      "Training  Accuacy : 1.00 \n",
      "\n",
      "Iter              : 85000  \n",
      "Minibatch Loss    : 0.00\n",
      "Training  Accuacy : 1.00 \n",
      "\n",
      "Iter              : 90000  \n",
      "Minibatch Loss    : 0.10\n",
      "Training  Accuacy : 0.98 \n",
      "\n",
      "Iter              : 95000  \n",
      "Minibatch Loss    : 0.06\n",
      "Training  Accuacy : 0.98 \n",
      "\n",
      "Optimization Finished!\n",
      "Testing Accuracy : 0.99 \n",
      "\n",
      "Model saved in file: Model/lenet-100000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph = tf.get_default_graph())\n",
    "\n",
    "    step = 1\n",
    "\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "        if step % display_step == 0:\n",
    "            # calculate batch loss and accuracy\n",
    "            loss, acc, summary = sess.run([cost, accuracy, merged_summary_op], \\\n",
    "                                          feed_dict = {x: batch_x, y: batch_y, \\\n",
    "                                                       keep_prob: 1.})\n",
    "\n",
    "            summary_writer.add_summary(summary, step * batch_size)\n",
    "\n",
    "            print(\"Iter              : %d  \" %(step * batch_size))\n",
    "            print(\"Minibatch Loss    : %.2f\" %(loss))\n",
    "            print(\"Training  Accuacy : %.2f\" %(acc), '\\n')\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    print(\"Testing Accuracy : %.2f\" %(sess.run(accuracy, feed_dict =  \\\n",
    "                                               {x: mnist.test.images, \\\n",
    "                                                y: mnist.test.labels, \\\n",
    "                                                keep_prob: 1.})), '\\n')\n",
    "\n",
    "    # Save model weights to disk\n",
    "    save_path = saver.save(sess, model_path, global_step = step * batch_size)\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ckpt_test(graph):\n",
    "    x = graph.get_tensor_by_name(\"X:0\")\n",
    "    y = graph.get_tensor_by_name(\"Y:0\")\n",
    "    keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "    accuracy  = graph.get_tensor_by_name(\"accuracy:0\")\n",
    "    \n",
    "    print(\"Testing Accuracy : %.2f\" %(sess.run(accuracy, feed_dict =  \\\n",
    "                                               {x: mnist.test.images, \\\n",
    "                                                y: mnist.test.labels, \\\n",
    "                                                keep_prob: 1.})))\n",
    "\n",
    "def show_identity(graph):\n",
    "    for i in graph.get_operations():\n",
    "        print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/lenet-100000\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "Converted 8 variables to const ops.\n",
      "Testing Accuracy : 0.99\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(\"Model/\")) \n",
    "    graph = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, \n",
    "                                                         [\"Y_hat\", \\\n",
    "                                                          \"cost\",  \\\n",
    "                                                          \"accuracy\"])\n",
    "    tf.train.write_graph(graph, \"Model/\", \"graph.pb\", as_text=False)\n",
    "\n",
    "    test_mode = True\n",
    "    if test_mode:\n",
    "        graph = tf.get_default_graph()\n",
    "        ckpt_test(graph)\n",
    "        #show_identity(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pb_test(graph_def):\n",
    "    x = tf.placeholder(tf.float32, [None, n_input], name = 'X')\n",
    "    y = tf.placeholder(tf.float32, [None, n_classes], name = 'Y')\n",
    "    keep_prob = tf.placeholder(tf.float32, name = \"keep_prob\") #dropout (keep probability)\n",
    "\n",
    "    accuracy = tf.import_graph_def(graph_def, input_map =      \\\n",
    "                                   {\"X:0\": x, \"Y:0\": y,        \\\n",
    "                                    \"keep_prob:0\": keep_prob}, \\\n",
    "                                   return_elements = [\"accuracy:0\"])\n",
    "\n",
    "    print(\"Testing Accuracy : %.2f\" %(sess.run(accuracy, feed_dict =  \\\n",
    "                                               {x: mnist.test.images, \\\n",
    "                                                y: mnist.test.labels, \\\n",
    "                                                keep_prob: 1.})[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy : 0.99\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    with open(\"Model/graph.pb\", \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        pb_test(graph_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=TensorBoard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r MNIST_data/ TensorBoard/ Model/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
